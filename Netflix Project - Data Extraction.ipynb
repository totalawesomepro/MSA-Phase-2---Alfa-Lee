{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import praw\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from keys import client_id, client_secret, username"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing Netflix shows dataset (Kaggle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to there being no official Netflix API for me to gather data on Netflix shows and their respective genre, I have instead decided to use this dataset I found on Kaggle, which consists of TV shows and movies available on Netflix as of 2019. The dataset was collected from Flixable which is a third-party Netflix search engine.\n",
    "\n",
    "Link: https://www.kaggle.com/shivamb/netflix-shows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix_shows = pd.read_csv(\"netflix_titles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix_shows.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6234, 12)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netflix_shows.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping irrelevant columns (for my aims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping columns\n",
    "netflix_shows = netflix_shows.drop(columns = [\"director\", \"cast\", \"rating\", \"duration\", \"description\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6234, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netflix_shows.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am also going to remove some titles which are also commonly used words, as well as titles I know are outliers, e.g. removing \"Philadelphia\" as I know the matches are false matches with \"It's Always Sunny in Philadelphia\" - which is not in the Netflix dataset.\n",
    "\n",
    "Thankfully, all these titles are quite unpopular! (Appears very little in top posts results / not at all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_words = [\"Philadelphia\", \"Next\", \"After\", \"Sometimes\", \"Game\", \"Episodes\", \"Life\", \"Security\", \"Victor\", \"Money\",\n",
    "                \"Together\", \"Rotten\", \"Close\", \"Tiger\", \"Justice\", \"Last\", \"Wanted\"]\n",
    "remove_words_index = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in remove_words:\n",
    "    remove_words_index.append(netflix_shows.loc[netflix_shows[\"title\"] == word].index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List comprehension to \"flatten\" list\n",
    "remove_words_index = [x for y in remove_words_index for x in y]\n",
    "remove_words_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping rows\n",
    "netflix_shows = netflix_shows.drop(remove_words_index, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6215, 7)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netflix_shows.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am now going to sort by length for the \"title\" column, descending.\n",
    "\n",
    "And also resetting the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix_shows.index = netflix_shows[\"title\"].str.len()\n",
    "netflix_shows = netflix_shows.sort_index(ascending = False)\n",
    "netflix_shows = netflix_shows.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix_shows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping rows in which the len(title) is <= 3 characters. This is because short phrases can easily be false matches later on when I am matching the Netflix title to the Reddit Submission.\n",
    "\n",
    "Unfortunately as a result, these titles won't be considered in my sentiment analysis. (Interestingly, they are also not very popular!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Netflix titles with 3 or less characters in length start at index 6168\n",
    "netflix_shows.loc[netflix_shows[\"title\"].str.len() <= 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keeping rows up to index 6167 (dropping rows 6168 and after)\n",
    "netflix_shows = netflix_shows.loc[:6167]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix_shows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing to a new csv\n",
    "netflix_shows.to_csv(\"netflix_titles_v2.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Collecting the Posts from r/Netflix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix_shows = pd.read_csv(\"netflix_titles_v2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialising a Reddit instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(client_id=client_id,\n",
    "                     client_secret=client_secret,\n",
    "                     user_agent=f\"android:my_app:v1 (by /u/{username})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling the Reddit API and building a dataframe from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix = reddit.subreddit(\"netflix\")\n",
    "\n",
    "# Get the top 1000 posts, with title, url, body, upvotes, timestamp, and an index that serves as a key between\n",
    "# the posts and the comments we collect later\n",
    "posts = []\n",
    "for index, post in enumerate(netflix.top(limit = 1000)):\n",
    "    posts.append([post.title, post.selftext, \"https://www.reddit.com\" + post.permalink, post.score, post.created_utc, index])\n",
    "\n",
    "# Converting into DataFrame\n",
    "posts = pd.DataFrame(posts, columns = [\"Submission\", \"Body\", \"URL\", \"Upvotes\", \"Time\", \"Key\"])\n",
    "\n",
    "# Changing from UTC time to standard timestamp\n",
    "posts.Time = posts.Time.apply(lambda x: pd.to_datetime(datetime.datetime.fromtimestamp(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(988, 6)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looks like we have only gathered 988 posts! (out of a total of ~118000 total submissions)\n",
    "posts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I am looking for specifically posts which are discussions based around a TV show / movie. So first filter out posts which don't contain a TV show / movie title, and keep the posts which do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Jim & Andy: The Great Beyond - Featuring a Ver...\n",
       "1    The Power of Grayskull: The Definitive History...\n",
       "2    Mike Birbiglia: What I Should Have Said Was No...\n",
       "3    Steve Martin and Martin Short: An Evening You ...\n",
       "4    Cultivating the Seas: History and Future of th...\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List of unique Netflix titles\n",
    "titles = netflix_shows[\"title\"]\n",
    "titles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I initially tried regex, but it didn't work out, which is fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Substrings have special characters such as $ and ^ which I wanted to match literally. These characters have specific\n",
    "# meanings in the context of regular expressions and will affect the matching. So, I had to make my list of\n",
    "# substrings (titles) \"safer\" by escaping non-alphanumeric characters with re.escape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# titles_safe = [re.escape(t) for t in titles]\n",
    "# titles_safe[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the regex | character to try to match each of the substrings in the Submission title.\n",
    "# posts = posts.loc[posts[\"Submission\"].str.contains(\"|\".join(titles_safe))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a for loop to match the corresponding Netflix title for each Reddit post (later adding 2 columns \"Title\" and \"Genres\" as well). Since I sorted my Netflix titles dataset from longest title to shortest, the following loop will match the longer titles before matching a shorter one, which is what I want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty column for the corresponding Netflix title\n",
    "posts.insert(1, \"Netflix_Title\", \"\")\n",
    "\n",
    "# Creating empty column for the corresponding Genres (listed in)\n",
    "posts.insert(2, \"Genres\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a for loop to match the corresponding Netflix title for each Reddit post\n",
    "\n",
    "# Storing the index of matching rows here\n",
    "netflix_index = []\n",
    "\n",
    "# Storing the matching titles here\n",
    "netflix_match_titles = []\n",
    "\n",
    "# Storing the corresponding genres here\n",
    "netflix_genres = []\n",
    "\n",
    "count = 0\n",
    "for line in posts[\"Submission\"]:\n",
    "    for title in titles:\n",
    "        if title in line:\n",
    "            count += 1\n",
    "            netflix_index.append(posts.index[posts[\"Submission\"] == line].tolist())\n",
    "            netflix_match_titles.append(title)\n",
    "            netflix_genres.append(netflix_shows[netflix_shows[\"title\"] == title].listed_in.tolist())\n",
    "            print(str(count) + \": \" + title + \" - index \" + str(posts.index[posts[\"Submission\"] == line].tolist()))\n",
    "            print(line + \"\\n\")\n",
    "            break\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List comprehension to \"flatten\" netflix_index\n",
    "netflix_index = [x for y in netflix_index for x in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "522"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# There are actually duplicates for 2 index values - at indices 205 and 247, removing them now\n",
    "netflix_index.pop(205)\n",
    "netflix_index.pop(247)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keeping only rows that match the index created in the for loop above\n",
    "posts = posts.loc[netflix_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the matching titles to the \"Netflix_Title\" column\n",
    "posts[\"Netflix_Title\"] = netflix_match_titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the matching genres to the Genres column\n",
    "posts[\"Genres\"] = netflix_genres\n",
    "\n",
    "# Stripping the square brackets and single speech marks\n",
    "posts[\"Genres\"] = posts[\"Genres\"].str.strip(\"[]'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetting the index and Key columns\n",
    "posts.reset_index(drop = True, inplace = True)\n",
    "posts = posts.drop(columns = [\"Key\"])\n",
    "posts[\"Key\"] = posts.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Submission</th>\n",
       "      <th>Netflix_Title</th>\n",
       "      <th>Genres</th>\n",
       "      <th>Body</th>\n",
       "      <th>URL</th>\n",
       "      <th>Upvotes</th>\n",
       "      <th>Time</th>\n",
       "      <th>Key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Netflix executives say the success of 'Bright'...</td>\n",
       "      <td>Bright</td>\n",
       "      <td>Action &amp; Adventure, Sci-Fi &amp; Fantasy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/netflix/comments/7t2f...</td>\n",
       "      <td>6802</td>\n",
       "      <td>2018-01-26 18:11:49</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Netflix Fires Kevin Spacey from ‘House of Cards’</td>\n",
       "      <td>House of Cards</td>\n",
       "      <td>TV Dramas, TV Thrillers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/netflix/comments/7ao8...</td>\n",
       "      <td>6504</td>\n",
       "      <td>2017-11-04 15:47:43</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Netflix has Cloverfield 3</td>\n",
       "      <td>Cloverfield</td>\n",
       "      <td>Action &amp; Adventure, Horror Movies, Sci-Fi &amp; Fa...</td>\n",
       "      <td>Edit: Streaming starts post game</td>\n",
       "      <td>https://www.reddit.com/r/netflix/comments/7vav...</td>\n",
       "      <td>5597</td>\n",
       "      <td>2018-02-05 13:23:43</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Witcher is Netflix's highest rated series</td>\n",
       "      <td>The Witcher</td>\n",
       "      <td>TV Action &amp; Adventure, TV Dramas, TV Mysteries</td>\n",
       "      <td>https://www.forbes.com/sites/paultassi/2019/12...</td>\n",
       "      <td>https://www.reddit.com/r/netflix/comments/eekm...</td>\n",
       "      <td>4891</td>\n",
       "      <td>2019-12-24 02:30:46</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Netflix has won its first Oscar, for Icarus</td>\n",
       "      <td>Icarus</td>\n",
       "      <td>Documentaries, Sports Movies</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/netflix/comments/8238...</td>\n",
       "      <td>4632</td>\n",
       "      <td>2018-03-05 17:03:47</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>Master of None season 2 premieres May 12 [ALL]</td>\n",
       "      <td>Master of None</td>\n",
       "      <td>TV Comedies</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/netflix/comments/5zkl...</td>\n",
       "      <td>631</td>\n",
       "      <td>2017-03-16 06:03:06</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>BoJack Horseman | Season 4 Official Trailer [H...</td>\n",
       "      <td>BoJack Horseman</td>\n",
       "      <td>TV Comedies</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/netflix/comments/6vri...</td>\n",
       "      <td>627</td>\n",
       "      <td>2017-08-25 03:15:41</td>\n",
       "      <td>411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>House of Cards final season is coming November 2</td>\n",
       "      <td>House of Cards</td>\n",
       "      <td>TV Dramas, TV Thrillers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/netflix/comments/95c0...</td>\n",
       "      <td>624</td>\n",
       "      <td>2018-08-08 02:15:57</td>\n",
       "      <td>412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>Black Mirror: Striking Vipers | Official Trailer</td>\n",
       "      <td>Black Mirror</td>\n",
       "      <td>British TV Shows, International TV Shows, TV D...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.reddit.com/r/netflix/comments/brbc...</td>\n",
       "      <td>622</td>\n",
       "      <td>2019-05-22 02:52:45</td>\n",
       "      <td>413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>Dirk Gently is like Sherlock meets Legion and ...</td>\n",
       "      <td>Sherlock</td>\n",
       "      <td>British TV Shows, Crime TV Shows, Internationa...</td>\n",
       "      <td>Dirk Gently is one of those shows that you wat...</td>\n",
       "      <td>https://www.reddit.com/r/netflix/comments/7yep...</td>\n",
       "      <td>622</td>\n",
       "      <td>2018-02-19 03:57:50</td>\n",
       "      <td>414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>415 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Submission    Netflix_Title  \\\n",
       "0    Netflix executives say the success of 'Bright'...           Bright   \n",
       "1     Netflix Fires Kevin Spacey from ‘House of Cards’   House of Cards   \n",
       "2                            Netflix has Cloverfield 3      Cloverfield   \n",
       "3        The Witcher is Netflix's highest rated series      The Witcher   \n",
       "4          Netflix has won its first Oscar, for Icarus           Icarus   \n",
       "..                                                 ...              ...   \n",
       "410     Master of None season 2 premieres May 12 [ALL]   Master of None   \n",
       "411  BoJack Horseman | Season 4 Official Trailer [H...  BoJack Horseman   \n",
       "412   House of Cards final season is coming November 2   House of Cards   \n",
       "413   Black Mirror: Striking Vipers | Official Trailer     Black Mirror   \n",
       "414  Dirk Gently is like Sherlock meets Legion and ...         Sherlock   \n",
       "\n",
       "                                                Genres  \\\n",
       "0                 Action & Adventure, Sci-Fi & Fantasy   \n",
       "1                              TV Dramas, TV Thrillers   \n",
       "2    Action & Adventure, Horror Movies, Sci-Fi & Fa...   \n",
       "3       TV Action & Adventure, TV Dramas, TV Mysteries   \n",
       "4                         Documentaries, Sports Movies   \n",
       "..                                                 ...   \n",
       "410                                        TV Comedies   \n",
       "411                                        TV Comedies   \n",
       "412                            TV Dramas, TV Thrillers   \n",
       "413  British TV Shows, International TV Shows, TV D...   \n",
       "414  British TV Shows, Crime TV Shows, Internationa...   \n",
       "\n",
       "                                                  Body  \\\n",
       "0                                                  NaN   \n",
       "1                                                  NaN   \n",
       "2                     Edit: Streaming starts post game   \n",
       "3    https://www.forbes.com/sites/paultassi/2019/12...   \n",
       "4                                                  NaN   \n",
       "..                                                 ...   \n",
       "410                                                NaN   \n",
       "411                                                NaN   \n",
       "412                                                NaN   \n",
       "413                                                NaN   \n",
       "414  Dirk Gently is one of those shows that you wat...   \n",
       "\n",
       "                                                   URL  Upvotes  \\\n",
       "0    https://www.reddit.com/r/netflix/comments/7t2f...     6802   \n",
       "1    https://www.reddit.com/r/netflix/comments/7ao8...     6504   \n",
       "2    https://www.reddit.com/r/netflix/comments/7vav...     5597   \n",
       "3    https://www.reddit.com/r/netflix/comments/eekm...     4891   \n",
       "4    https://www.reddit.com/r/netflix/comments/8238...     4632   \n",
       "..                                                 ...      ...   \n",
       "410  https://www.reddit.com/r/netflix/comments/5zkl...      631   \n",
       "411  https://www.reddit.com/r/netflix/comments/6vri...      627   \n",
       "412  https://www.reddit.com/r/netflix/comments/95c0...      624   \n",
       "413  https://www.reddit.com/r/netflix/comments/brbc...      622   \n",
       "414  https://www.reddit.com/r/netflix/comments/7yep...      622   \n",
       "\n",
       "                    Time  Key  \n",
       "0    2018-01-26 18:11:49    0  \n",
       "1    2017-11-04 15:47:43    1  \n",
       "2    2018-02-05 13:23:43    2  \n",
       "3    2019-12-24 02:30:46    3  \n",
       "4    2018-03-05 17:03:47    4  \n",
       "..                   ...  ...  \n",
       "410  2017-03-16 06:03:06  410  \n",
       "411  2017-08-25 03:15:41  411  \n",
       "412  2018-08-08 02:15:57  412  \n",
       "413  2019-05-22 02:52:45  413  \n",
       "414  2018-02-19 03:57:50  414  \n",
       "\n",
       "[415 rows x 8 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(415, 8)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looking good!\n",
    "\n",
    "We now have roughly 40% (~415) of the top 988 posts on r/Netflix, that are discussions based around a TV show / movie.\n",
    "\n",
    "We have successfully attached each to each post their respective Netflix title and genres listed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing the posts to a csv\n",
    "posts.to_csv(\"Netflix_Posts.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Collecting the comments from each post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading in relevant files\n",
    "netflix_shows = pd.read_csv(\"netflix_titles_v2.csv\")\n",
    "posts = pd.read_csv(\"Netflix_Posts.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to collect every comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_replies(key, url):\n",
    "    ''' \n",
    "    params pandas series row: each row of the dataframe we built above in the form of a panda series\n",
    "    Returns a pandas DataFrame, where each row represents an individual comment\n",
    "    '''\n",
    "    submission = reddit.submission(url = url)\n",
    "    submission.comments.replace_more(limit = None)\n",
    "    comment_queue = submission.comments[:]\n",
    "    \n",
    "    table = {\"Reply\":[], \"Upvote\":[], \"Time\":[], \"Key\":[]}\n",
    "    \n",
    "    while comment_queue:\n",
    "        comment = comment_queue.pop(0)\n",
    "        table[\"Reply\"].append(comment.body)\n",
    "        table[\"Time\"].append(comment.created_utc)\n",
    "        table[\"Upvote\"].append(comment.score)\n",
    "        table[\"Key\"].append(key)\n",
    "        comment_queue.extend(comment.replies)\n",
    "    \n",
    "    return pd.DataFrame.from_dict(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating dataframe of comments. Using list comprehensions will speed things up slightly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a list of tuples that contains the Key and URL for each row\n",
    "# First value of tuple is Key, second is URL\n",
    "keys = posts.Key.tolist()\n",
    "urls = posts.URL.tolist()\n",
    "tuples = list(zip(keys, urls))\n",
    "\n",
    "# Generate our comments dataframe using list comprehensions\n",
    "comments = pd.concat([collect_replies(x[0], x[1]) for x in tuples])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Took me ~15 minutes to generate the comments for 415 posts!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again, converting the timsteamp from UTC to a standard format\n",
    "comments.Time = comments.Time.apply(lambda x: pd.to_datetime(datetime.datetime.fromtimestamp(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reply</th>\n",
       "      <th>Upvote</th>\n",
       "      <th>Time</th>\n",
       "      <th>Key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I didn't go into Bright expecting a cinematic ...</td>\n",
       "      <td>2079</td>\n",
       "      <td>2018-01-26 21:23:11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It was pretty good. It was a solid B. Pretty m...</td>\n",
       "      <td>1529</td>\n",
       "      <td>2018-01-26 18:59:11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I enjoyed it, I would watch another.  It did n...</td>\n",
       "      <td>244</td>\n",
       "      <td>2018-01-27 00:16:08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This is a pretty terrible argument. There no f...</td>\n",
       "      <td>25</td>\n",
       "      <td>2018-01-27 04:42:08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Everything was great about it except the plot....</td>\n",
       "      <td>149</td>\n",
       "      <td>2018-01-26 23:37:54</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Reply  Upvote  \\\n",
       "0  I didn't go into Bright expecting a cinematic ...    2079   \n",
       "1  It was pretty good. It was a solid B. Pretty m...    1529   \n",
       "2  I enjoyed it, I would watch another.  It did n...     244   \n",
       "3  This is a pretty terrible argument. There no f...      25   \n",
       "4  Everything was great about it except the plot....     149   \n",
       "\n",
       "                 Time  Key  \n",
       "0 2018-01-26 21:23:11    0  \n",
       "1 2018-01-26 18:59:11    0  \n",
       "2 2018-01-27 00:16:08    0  \n",
       "3 2018-01-27 04:42:08    0  \n",
       "4 2018-01-26 23:37:54    0  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57732, 4)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have gathered 57732 comments and replies from 415 posts!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments.to_csv(\"Netflix_Comments.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
